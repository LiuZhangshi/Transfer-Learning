{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras import optimizers \n",
    "import keras.datasets\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/liuzhangshi/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Specify input shape. Since we are using dataset cifar10, the input size should be (32,32,3)\n",
    "input_tensor = Input(shape = (32, 32, 3))\n",
    "\n",
    "# Borrow vgg model as the base model. Use partial pre-trained weights, delete the top layer\n",
    "vgg_model = applications.VGG16(weights = 'imagenet', \n",
    "                               include_top = False, \n",
    "                               input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the layers in layer_dict\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# If you don't want to use the complete vgg model, you can pick one layer as your last vgg block\n",
    "# Then add your own fc layers and softmax\n",
    "# Here I picked block3_pool. It's probably not the best choice for the application. I just wanna show how to do this.\n",
    "out_layer = layer_dict['block3_pool'].output\n",
    "\n",
    "# Stack new layers \n",
    "# First flatten the conv layer, then add fc layer, then softmax. Again, it's may not be a good choice, just an example.\n",
    "out_layer = Flatten()(out_layer)\n",
    "out_layer = Dense(128, \n",
    "          kernel_initializer='random_uniform',\n",
    "          bias_initializer='zeros', \n",
    "          activation = 'relu')(out_layer)\n",
    "out_layer = Dense(10, \n",
    "          kernel_initializer='random_uniform',\n",
    "          bias_initializer='zeros',\n",
    "          activation = 'softmax')(out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzhangshi/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cur_model = Model(input = vgg_model.input, output = out_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,261,194\n",
      "Trainable params: 525,706\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decide whether you want to change the pre-trained weights or not.\n",
    "# Here I keep the first 10 layers' weights\n",
    "for layer in cur_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "cur_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify optimizor, here Adam with learning rate 0.001\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# model compile\n",
    "# The loss func, binary_crossentropy for 2 labels, \n",
    "# and categorical_crossentropy for more than 2 labels. Here we have 10 categories\n",
    "cur_model.compile(loss = 'categorical_crossentropy',\n",
    "                 optimizer = optim,\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# The y values are integers, but our model softmax output is probability distribution. Each component\n",
    "# will be interval (0,1) and sum up to 1.\n",
    "# Here we use to_categorical to convert y to one-hot vectors before training\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loaded x data are integers, we need to convert them to float32 type for the following preprocessing actions.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# data scaling \n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# The vgg author wrote in the paper that:\n",
    "# \"The only preprocessing we do is subtracting the mean RGB value, computed on the training set, from each pixel.\"\n",
    "# Thus the 'preprocess_input' func imported from 'keras.applications.vgg' will only do the mean subtract for preprocess\n",
    "#x_train = preprocess_input(x_train)\n",
    "#x_test = preprocess_input(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import LambdaCallback\n",
    "#print_weights = LambdaCallback(on_epoch_begin=lambda batch, logs: print(cur_model.layers[9].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/liuzhangshi/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 423s 8ms/step - loss: 1.2231 - acc: 0.6362\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 390s 8ms/step - loss: 0.7894 - acc: 0.7309\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 361s 7ms/step - loss: 0.7180 - acc: 0.7564\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.6755 - acc: 0.7710\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.6466 - acc: 0.7819\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 365s 7ms/step - loss: 0.6203 - acc: 0.7933\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.5882 - acc: 0.8005\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 355s 7ms/step - loss: 0.5748 - acc: 0.8066\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 547s 11ms/step - loss: 0.5492 - acc: 0.8154\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.5438 - acc: 0.8168\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 416s 8ms/step - loss: 0.5248 - acc: 0.8236\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.5135 - acc: 0.8269\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 385s 8ms/step - loss: 0.5041 - acc: 0.8332\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 395s 8ms/step - loss: 0.4923 - acc: 0.8359\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 387s 8ms/step - loss: 0.4757 - acc: 0.8403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13dfea5c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 15\n",
    "cur_model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 65s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7945564816951751, 0.7649]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction-----------------------------------------------------------------\n",
    "# 'load_img' returns a PIL image instance.\n",
    "image = load_img('truck.jpg', target_size=(32, 32), color_mode = 'rgb')\n",
    "\n",
    "# Keras provides the img_to_array() function for converting a loaded image in PIL format \n",
    "# into a NumPy array for use with models.\n",
    "image = img_to_array(image)\n",
    "\n",
    "# The input of the model should be (num_samples, img_shape[0], img_shape[1], img_shape[2])\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# Convert integers to float32\n",
    "image = image.astype('float32')\n",
    "\n",
    "# preprocessing\n",
    "image /= 255.\n",
    "#image = preprocess_input(image)\n",
    "\n",
    "pred = cur_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a truck!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "_, i = np.unravel_index(pred.argmax(), pred.shape)\n",
    "\n",
    "if i == 0:\n",
    "    print(\"It's a airplane!\")\n",
    "elif i == 1:\n",
    "    print(\"It's a automobile!\")\n",
    "elif i == 2:\n",
    "    print(\"It's a bird!\")\n",
    "elif i == 3:\n",
    "    print(\"It's a cat!\")\n",
    "elif i == 4:\n",
    "    print(\"It's a deer!\")\n",
    "elif i == 5:\n",
    "    print(\"It's a dog!\")\n",
    "elif i == 6:\n",
    "    print(\"It's a frog!\")\n",
    "elif i == 7:\n",
    "    print(\"It's a horse!\")\n",
    "elif i == 8:\n",
    "    print(\"It's a ship!\")\n",
    "elif i == 9:\n",
    "    print(\"It's a truck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_model.save_weights('vgg_cifar10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
