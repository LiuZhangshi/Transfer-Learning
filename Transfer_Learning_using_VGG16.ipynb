{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning using VGG16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiuZhangshi/Transfer-Learning/blob/master/Transfer_Learning_using_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODH1-TvoD2jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras import optimizers \n",
        "import keras.datasets\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbSsqnDhq7wf",
        "colab_type": "text"
      },
      "source": [
        "Default input for vgg16 is (224, 224, 3).\n",
        "Here we are using CIFAR10 which has small image classification Dataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images. Thus we specify the input to be of shape (32, 32, 3). Moreover, we don't need the fully connected layers in VGG16 while keep the weights of other layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGkeerWYWxgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape = (32, 32, 3))\n",
        "vgg_model = applications.VGG16(weights = 'imagenet', \n",
        "                               include_top = False, \n",
        "                               input_tensor = input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICAEcp3xsUAm",
        "colab_type": "text"
      },
      "source": [
        "We create a new network using pre-trained bottom layers of vgg16, up to layer with the name 'block3_pool'. Here we made a dictionary mapping layer names to the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rbxeuQ3rNtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
        "x = layer_dict['block3_pool'].output\n",
        "# Stacking new layers \n",
        "x = Flatten()(x)\n",
        "x = Dense(128, \n",
        "          kernel_initializer='random_uniform',\n",
        "          bias_initializer='zeros', \n",
        "          activation = 'relu')(x)\n",
        "x = Dense(10, \n",
        "          kernel_initializer='random_uniform',\n",
        "          bias_initializer='zeros',\n",
        "          activation = 'softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--K10uZltfkr",
        "colab_type": "text"
      },
      "source": [
        "Create new model. Note this is not a Sequential() model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8XrCOkHtLYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cur_model = Model(input = vgg_model.input, output = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5y2PPc9uKhg",
        "colab_type": "text"
      },
      "source": [
        "Keep the pre-trained weights of VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl5HuRxotidT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "3a85b53a-9bf1-4225-b16b-0afca1dcf80b"
      },
      "source": [
        "for layer in cur_model.layers[:10]:\n",
        "  layer.trainable = False\n",
        "cur_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,261,194\n",
            "Trainable params: 525,706\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq00pKFsuR3k",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model using Adam optimizer with learning rate 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EiDJuXbuyqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "cur_model.compile(loss = 'categorical_crossentropy',\n",
        "                 optimizer = optim,\n",
        "                 metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zJMQz97wa16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UJ-DcfSwdQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0ae43cb2-8343-45d3-f565-9692e6b84b78"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmSEMp9TxNNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "937edc93-a98c-4770-82e1-446d5e8ef5c8"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmWNK1hMud7J",
        "colab_type": "text"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwVwiH1SxbBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMA-mw1ourxh",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buKXNd_mxjdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "print_weights = LambdaCallback(on_epoch_begin=lambda batch, logs: print(cur_model.layers[9].get_weights()))\n",
        "cur_model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, callbacks = [print_weights])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upQwn58swGTj",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model using test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wnb7dTVvbTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f2d0ea9-83b5-43fd-a5a2-22142a79d970"
      },
      "source": [
        "cur_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 70s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8247881430149079, 0.7581]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfve9g9jvs7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLoaj-QKwK6g",
        "colab_type": "text"
      },
      "source": [
        "Summary:\n",
        "The test accuracy is about 76% when epoch = 20, which is still underfitting.\n",
        "Try to add one more fc layer of size 64 and use more epoch like 30 or 50."
      ]
    }
  ]
}